[["Evaluate", "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative."], ["Evaluate", "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions."], ["Evaluate", "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels."], ["Analyze", "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?"], ["Analyze", "As of 2020, which architecture is best for classifying high-resolution images?"], ["Evaluate", "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment."], ["Apply", "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?"], ["Evaluate", "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain."], ["Analyze", "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?"], ["Create", "As the number of training examples goes to infinity, your model trained on that data will have:"], ["Evaluate", "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite."], ["Analyze", "_ refers to a model that can neither model the training data nor generalize to new data."], ["Evaluate", "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors."], ["Evaluate", "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line."], ["Analyze", "High entropy means that the partitions in classification are"], ["Evaluate", "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training."], ["Create", "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that"], ["Analyze", "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):"], ["Analyze", "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:"], ["Create", "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer."]]